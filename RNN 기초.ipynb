{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXg79CcV/eNoOWDNtt7WH5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. 순환 신경망(Recurrent Neural Network)\n","- [RNN](https://wikidocs.net/22886)\n","- 입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델\n","- 시퀀스 : 번역하고자 하는 단어의 문장\n","- 연속적인 데이터를 NN에 하나씩 순차적으로 넣어 처리하는 모델\n"],"metadata":{"id":"1xInamVV-x8Y"}},{"cell_type":"markdown","source":["### 1-1. RNN 동작 방식\n","- 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 다시 출력층 방향으로 보내면서 은닉층 노드의 다음 계산의 입력으로 보내는 것이 특징\n","- 셀(cell) : 은닉층에서 활성화 함수를 통해 나온 결과를 내보내는 역할을 하는 노드 이전의 값을 기억하려고 하는 일종의 메모리 역할 수행\n","- 은닉 상태(hidden state):  셀이 출력층 방향 또는 다음 시점인 t+1의 자신에게 보내는 값"],"metadata":{"id":"XivDLQwR-4uQ"}},{"cell_type":"markdown","source":["```\n","rnn = torch.nn.RNN(input_size, hidden_size)\n","outputs, state = rnn(input_data)\n","# state = hidden size\n","```"],"metadata":{"id":"d0b7ArStbRaP"}},{"cell_type":"markdown","source":["### 1-2. input size\n","- 단어가 입력되면 각 글자를 벡터의 형태로 변환하여 one-hot encoding 해주는 과정이 필요\n","- 'hello'\n","  - h = [1,0,0,0]\n","  - e = [0,1,0,0]\n","  - l = [0,0,1,0]\n","  - o = [0,0,0,1]\n","- input_size = 4\n","- input_data의 세번쨰 차원으로 입력"],"metadata":{"id":"FR-RHoPibQKE"}},{"cell_type":"markdown","source":["### 1-3. Hidden State Size\n","\n","- hidden state의 size는 output shape의 세번째 차원\n","- output size와 같음\n","- 셀에서 연산된 결과를 두 가지로 나눠 하나는 output으로 출력되고, 다른 하나는 hidden state로 다음 step에 그대로 전해짐"],"metadata":{"id":"PDyg_fcvcjMu"}},{"cell_type":"markdown","source":["### 1-4. Sequence Length\n","- Sequence가 총 몇개인지를 나타냄\n","- 'hello'\n","    - x0 = [1,0,0,0]\n","    - x1 = [0,1,0,0]\n","    - x2 = [0,0,1,0]\n","    - x3 = [0,0,1,0]\n","    - x4 = [0,0,0,1]\n","- 'hello'를 입력으로 보내면 sequence length는 5\n","- Pytorch에서는 모델이 sequence length를 알아서 파악하기 때문에 파라미터로 전달해 줄 필요가 없음"],"metadata":{"id":"smYjiHUQdiiO"}},{"cell_type":"markdown","source":["### 1-5. batch size\n","- 여러 데이터를 묶어 하나의 batch로 만들어 학습을 진행\n","- [h,e,l,l,o][e,o,l,l,l][l,l,e,e,l] 처럼 h,e,l,o를 가지고 만들 수 있는 데이터 중 3개를 하나의 batch로 묶어 학습을 진행함\n","- batch size를 모델에서 자동으로 파악하고 output data, input data에서의 첫번째 차원에 위치함"],"metadata":{"id":"5oV8Tp9MeXI4"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from torch.nn import RNN\n","import torch.nn as nn\n","\n","import torch.optim as optim"],"metadata":{"id":"ByMsLx6eeYq7","executionInfo":{"status":"ok","timestamp":1706161631772,"user_tz":-540,"elapsed":7973,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["input_size = 4\n","hidden_size = 2\n","epochs = 100\n","\n","h = [1,0,0,0]\n","e = [0,1,0,0]\n","l = [0,0,1,0]\n","o = [0,0,0,1]\n","\n","input_data_np = np.array([[h,e,l,l,o],[e,o,l,l,l],[l,l,e,e,l]], dtype=np.float32)\n","\n","input_data = torch.Tensor(input_data_np)\n","\n","rnn = RNN(input_size, hidden_size)\n","outputs, state = rnn(input_data)"],"metadata":{"id":"QTSfgXlufSBv","executionInfo":{"status":"ok","timestamp":1706161631773,"user_tz":-540,"elapsed":7,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wT9FAlh0fbVe","executionInfo":{"status":"ok","timestamp":1706161631773,"user_tz":-540,"elapsed":6,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}},"outputId":"f6a7a4c2-7c31-43c3-9292-ee9a9aac9dc8"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.4202,  0.4924],\n","         [ 0.3660,  0.7304],\n","         [-0.4599,  0.7581],\n","         [-0.4599,  0.7581],\n","         [-0.0087,  0.7611]]], grad_fn=<StackBackward0>)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# helloworld\n","test = 'hello! world'\n","# string_set = ['h','e','l','o','w','r','d']\n","string_set = list(set(test))\n","print(string_set)\n","\n","string_dic = {c: i for i, c in enumerate(string_set)}\n","print(string_dic)\n","\n","input_size = len(string_dic)\n","print(input_size)\n","hidden_size = len(string_dic)\n","print(hidden_size)\n","learning_rate = 0.1\n","\n","test_idx = [string_dic[c] for c in test]\n","print(test_idx)\n","x_data = [test_idx[:]]\n","print(x_data)\n","x_one_hot = [np.eye(input_size)[x] for x in x_data]\n","print(x_one_hot)\n","y_data = [test_idx[:]]\n","print(y_data)\n","\n","X = torch.FloatTensor(x_one_hot)\n","y = torch.LongTensor(y_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hvGbyLMglbQ","executionInfo":{"status":"ok","timestamp":1706163504718,"user_tz":-540,"elapsed":367,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}},"outputId":"b8b17603-4239-47fc-afd5-f5392425cf0b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['h', '!', 'w', ' ', 'l', 'r', 'e', 'o', 'd']\n","{'h': 0, '!': 1, 'w': 2, ' ': 3, 'l': 4, 'r': 5, 'e': 6, 'o': 7, 'd': 8}\n","9\n","9\n","[0, 6, 4, 4, 7, 1, 3, 2, 7, 5, 4, 8]\n","[[0, 6, 4, 4, 7, 1, 3, 2, 7, 5, 4, 8]]\n","[array([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 1.]])]\n","[[0, 6, 4, 4, 7, 1, 3, 2, 7, 5, 4, 8]]\n"]}]},{"cell_type":"code","source":["# RNN\n","# CrossEntropyLoss()\n","# Adam\n","# epoch: 100\n","# loss를 출력\n","\n","rnn = RNN(input_size, hidden_size)\n","loss_fun = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(rnn.parameters(), learning_rate)\n"],"metadata":{"id":"sKowOonf4zO5","executionInfo":{"status":"ok","timestamp":1706163510339,"user_tz":-540,"elapsed":1,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for i in range(100):\n","    optimizer.zero_grad()\n","    outputs, state = rnn(X)\n","    loss = loss_fun(outputs.view(-1, input_size), y.view(-1))\n","    loss.backward()\n","    optimizer.step()\n","\n","    result = outputs.data.numpy().argmax(axis=2)\n","    print(result)\n","    result_str = ''.join([string_set[ch] for ch in np.squeeze(result)])\n","    print(i, 'loss:', loss)\n","    print('prediction:', result, 'prediction_str:', result_str)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqCgNNsFB7y2","executionInfo":{"status":"ok","timestamp":1706163516619,"user_tz":-540,"elapsed":1189,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}},"outputId":"94d74e09-69b2-4589-c12b-01acb933bae9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[[3 3 3 3 3 3 7 3 3 3 3 3]]\n","0 loss: tensor(2.2635, grad_fn=<NllLossBackward0>)\n","prediction: [[3 3 3 3 3 3 7 3 3 3 3 3]] prediction_str:       o     \n","[[3 6 3 3 7 7 7 3 7 3 3 7]]\n","1 loss: tensor(2.0561, grad_fn=<NllLossBackward0>)\n","prediction: [[3 6 3 3 7 7 7 3 7 3 3 7]] prediction_str:  e  ooo o  o\n","[[3 6 4 4 7 1 7 3 7 3 4 8]]\n","2 loss: tensor(1.8555, grad_fn=<NllLossBackward0>)\n","prediction: [[3 6 4 4 7 1 7 3 7 3 4 8]] prediction_str:  ello!o o ld\n","[[4 6 4 4 7 1 7 3 7 4 4 8]]\n","3 loss: tensor(1.6793, grad_fn=<NllLossBackward0>)\n","prediction: [[4 6 4 4 7 1 7 3 7 4 4 8]] prediction_str: lello!o olld\n","[[4 6 4 4 7 1 3 4 7 4 4 8]]\n","4 loss: tensor(1.5399, grad_fn=<NllLossBackward0>)\n","prediction: [[4 6 4 4 7 1 3 4 7 4 4 8]] prediction_str: lello! lolld\n","[[0 6 4 4 7 1 4 2 7 4 4 8]]\n","5 loss: tensor(1.4313, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 4 2 7 4 4 8]] prediction_str: hello!lwolld\n","[[0 6 4 4 7 1 4 2 7 4 4 8]]\n","6 loss: tensor(1.3380, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 4 2 7 4 4 8]] prediction_str: hello!lwolld\n","[[0 6 4 4 7 1 4 2 7 5 4 8]]\n","7 loss: tensor(1.2525, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 4 2 7 5 4 8]] prediction_str: hello!lworld\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","8 loss: tensor(1.1758, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","9 loss: tensor(1.1094, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","10 loss: tensor(1.0519, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","11 loss: tensor(1.0022, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","12 loss: tensor(0.9603, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","13 loss: tensor(0.9256, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","14 loss: tensor(0.8975, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","15 loss: tensor(0.8750, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","16 loss: tensor(0.8569, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","17 loss: tensor(0.8422, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","18 loss: tensor(0.8303, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","19 loss: tensor(0.8204, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","20 loss: tensor(0.8119, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","21 loss: tensor(0.8047, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","22 loss: tensor(0.7984, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","23 loss: tensor(0.7928, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","24 loss: tensor(0.7879, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","25 loss: tensor(0.7836, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","26 loss: tensor(0.7798, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","27 loss: tensor(0.7764, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","28 loss: tensor(0.7734, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","29 loss: tensor(0.7707, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","30 loss: tensor(0.7684, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","31 loss: tensor(0.7663, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","32 loss: tensor(0.7644, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","33 loss: tensor(0.7627, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","34 loss: tensor(0.7612, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","35 loss: tensor(0.7599, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","36 loss: tensor(0.7587, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","37 loss: tensor(0.7576, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","38 loss: tensor(0.7566, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","39 loss: tensor(0.7558, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","40 loss: tensor(0.7550, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","41 loss: tensor(0.7543, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","42 loss: tensor(0.7536, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","43 loss: tensor(0.7530, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","44 loss: tensor(0.7524, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","45 loss: tensor(0.7519, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","46 loss: tensor(0.7515, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","47 loss: tensor(0.7510, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","48 loss: tensor(0.7506, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","49 loss: tensor(0.7502, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","50 loss: tensor(0.7499, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","51 loss: tensor(0.7495, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","52 loss: tensor(0.7492, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","53 loss: tensor(0.7489, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","54 loss: tensor(0.7486, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","55 loss: tensor(0.7483, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","56 loss: tensor(0.7481, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","57 loss: tensor(0.7478, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","58 loss: tensor(0.7476, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","59 loss: tensor(0.7474, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","60 loss: tensor(0.7472, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","61 loss: tensor(0.7469, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","62 loss: tensor(0.7467, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","63 loss: tensor(0.7465, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","64 loss: tensor(0.7464, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","65 loss: tensor(0.7462, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","66 loss: tensor(0.7460, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","67 loss: tensor(0.7458, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","68 loss: tensor(0.7457, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","69 loss: tensor(0.7455, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","70 loss: tensor(0.7454, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","71 loss: tensor(0.7452, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","72 loss: tensor(0.7451, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","73 loss: tensor(0.7449, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","74 loss: tensor(0.7448, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","75 loss: tensor(0.7447, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","76 loss: tensor(0.7445, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","77 loss: tensor(0.7444, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","78 loss: tensor(0.7443, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","79 loss: tensor(0.7442, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","80 loss: tensor(0.7440, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","81 loss: tensor(0.7439, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","82 loss: tensor(0.7438, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","83 loss: tensor(0.7437, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","84 loss: tensor(0.7436, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","85 loss: tensor(0.7435, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","86 loss: tensor(0.7434, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","87 loss: tensor(0.7433, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","88 loss: tensor(0.7432, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","89 loss: tensor(0.7431, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","90 loss: tensor(0.7430, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","91 loss: tensor(0.7429, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","92 loss: tensor(0.7428, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","93 loss: tensor(0.7427, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","94 loss: tensor(0.7426, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","95 loss: tensor(0.7425, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","96 loss: tensor(0.7424, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","97 loss: tensor(0.7424, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","98 loss: tensor(0.7423, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n","[[0 6 4 4 7 1 3 2 7 5 4 8]]\n","99 loss: tensor(0.7422, grad_fn=<NllLossBackward0>)\n","prediction: [[0 6 4 4 7 1 3 2 7 5 4 8]] prediction_str: hello! world\n"]}]},{"cell_type":"markdown","source":["# 2. RNN의 단점\n","- 입력과 출력이 고정\n","- 기울기 소실\n","- 단점을 극복하기 위해 RNN의 발전 형태인 LSTM과 GRU를 사용(문제를 완벽히 해결하지 못함)"],"metadata":{"id":"hzeV3bi9L5vn"}},{"cell_type":"code","source":[],"metadata":{"id":"OoNugWPA7gRR","executionInfo":{"status":"aborted","timestamp":1706161269834,"user_tz":-540,"elapsed":5,"user":{"displayName":"DongHwi Kim","userId":"11971824741998230355"}}},"execution_count":null,"outputs":[]}]}